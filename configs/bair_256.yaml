# Experiment name
name: "bair_256"

# Dataset parameters
data:
  data_root: "/data/cvg/aram/hdf5/ours/BAIR_256_h5"
  input_size: 256
  crop_size: 256
  frames_per_sample: 16
  skip_frames: 0
  random_horizontal_flip: False
  aug: False
  albumentations: True

# Parameters of the model
model:
  # Defines the sigma min
  sigma: 0.0000001

  # Parameters for vector field regressor
  vector_field_regressor:
    state_size: 8
    state_res: [16, 16]
    inner_dim: 768
    depth: 4
    mid_depth: 5
    out_norm: "bn"

  # Parameters for the autoencoder
  autoencoder:
    # The architecture of the autoencoder [ours, ldm-vq, ldm-kl]
    type: "ldm-vq"
    config: "f16"
    ckpt_path: "/home/ad20n980/research/taming-transformers/logs/2022-10-27T22-22-52_bair_vqgan/checkpoints/last.ckpt"

# Parameters for the training
training:
  # Parameters for batch building
  batching:
    batch_size: 16
    num_workers: 7

  # Parameters for the optimizer
  optimizer:
    learning_rate: 0.0001
    weight_decay: 0.000005

    num_warmup_steps: 5000
    num_training_steps: 300000

  # Number of observations in the sequence
  num_observations: 16
  # Number of frames to use as initial conditioning
  condition_frames: 1
  # Nuber of frames to generate
  frames_to_generate: 15

  # Parameters for loss weighting
  loss_weights:
    flow_matching_loss: 1.0

# Parameters for the evaluation
evaluation:
  # Parameters for batch building
  batching:
    batch_size: 4
    num_workers: 8

  # Number of observations in the sequence
  num_observations: 16
  # Number of frames to use as initial conditioning
  condition_frames: 1
  # Nuber of frames to generate
  frames_to_generate: 15
  # Number of steps to use in the flow integration for generation
  steps: 100
